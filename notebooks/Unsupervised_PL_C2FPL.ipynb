{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# probability model\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nalist shape: (1609, 2)  total_T: 779951\n",
      "train_data shape: (779951, 10, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Use the I3D-based boundaries you generated (var-T, FNS ✗)\n",
    "nalist = np.load(r\"..\\list\\nalist_i3d.npy\")\n",
    "total_T = int(nalist[-1, 1])\n",
    "\n",
    "# concat_UCF.npy was created via np.memmap (raw float32 file), so load with memmap\n",
    "train_data = np.memmap(r\"..\\concat_UCF.npy\", dtype=\"float32\", mode=\"r\", shape=(total_T, 10, 2048))\n",
    "\n",
    "print(\"nalist shape:\", nalist.shape, \" total_T:\", total_T)\n",
    "print(\"train_data shape:\", train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video0 span: (0, 171) T0: 171\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: video-0 span in the concatenated memmap\n",
    "a0, b0 = map(int, nalist[0])\n",
    "print(\"video0 span:\", (a0, b0), \"T0:\", b0-a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1609"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_repr = []\n",
    "for i, (fromid, toid) in enumerate(nalist):\n",
    "    new_repr.append(train_data[fromid:toid])\n",
    "\n",
    "len(new_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nalist[0]: 0 171 len= 171\n",
      "slice x0: (171, 10, 2048)\n",
      "new_repr[0]: (171, 10, 2048)\n"
     ]
    }
   ],
   "source": [
    "nalist_i3d = np.load(r\"..\\list\\nalist_i3d.npy\")\n",
    "from0, to0 = nalist_i3d[0]\n",
    "print(\"nalist[0]:\", from0, to0, \"len=\", to0-from0)\n",
    "\n",
    "x0 = train_data[from0:to0]\n",
    "print(\"slice x0:\", x0.shape)        # 여기서 (171,10,2048) 나와야 정상\n",
    "\n",
    "print(\"new_repr[0]:\", new_repr[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 10, 2048)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_repr[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gauss(X):\n",
    "    m = X.shape[0]   # using only first dimension as we know it has only one feature - l2 norm\n",
    "    \n",
    "    mu = np.mean(X, axis=0)\n",
    "    var = np.cov(X.T)\n",
    "    \n",
    "    return mu, var\n",
    "\n",
    "def covariance_mat(X):\n",
    "    X = np.mean(X , axis= 1)\n",
    "    X =  X.transpose(1,0)\n",
    "    cov  = np.cov(X)\n",
    "\n",
    "    return cov\n",
    "\n",
    "def get_matrix(data):\n",
    "\n",
    "    l2_norm = np.sum(np.square(data), axis=2)\n",
    "    n_train_crop_l2_norm_mean = np.mean(l2_norm, axis= 1)\n",
    "\n",
    "    return n_train_crop_l2_norm_mean\n",
    "\n",
    "\n",
    "def diff_l2(new_repr):\n",
    "\n",
    "    l2_norms = []\n",
    "    for i in range(len(new_repr)):\n",
    "        l2_norms.append(get_matrix(new_repr[i]))\n",
    "\n",
    "    mean_v_l2 = []\n",
    "    for i in range(len(l2_norms)):\n",
    "        mean_v_l2.append(np.diff(l2_norms[i], n=1).max())\n",
    "    return mean_v_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for i in range(len(new_repr)):\n",
    "\n",
    "    param = get_matrix(new_repr[i])\n",
    "    mu, var = estimate_gauss(param)\n",
    "\n",
    "    params.append((mu, var, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1609, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427 0.2653822249844624\n",
      "The threshold of the score is -23.32\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import time\n",
    "\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, max_iter=150, random_state=0, covariance_type='spherical')\n",
    "# gmm_scores = gmm.score_samples(params)\n",
    "labels = gmm.fit_predict(params)\n",
    "\n",
    "y_gmm = gmm.fit_predict(params)\n",
    "print(y_gmm.sum(), y_gmm.sum() / len(y_gmm))\n",
    "\n",
    "\n",
    "score = y_gmm \n",
    "score = gmm.score_samples(params) \n",
    "pct_threshold = np.percentile(score, 3)\n",
    "print(f'The threshold of the score is {pct_threshold:.2f}') \n",
    "res = np.array([1 if x < pct_threshold else 0 for x in score]) \n",
    "print(res.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1182,), (427,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal_portion = np.where(labels == 1)[0]\n",
    "normal_portion = np.where(labels == 0)[0]\n",
    "normal_portion.shape, abnormal_portion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1182, 2), (427, 2))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_params = np.array(params)[normal_portion]\n",
    "a_params = np.array(params)[abnormal_portion]\n",
    "n_params.shape, a_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 1182)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abag = list(zip(list(np.array(params)[abnormal_portion]), abnormal_portion))\n",
    "nbag = list(zip(list(np.array(params)[normal_portion]), normal_portion))\n",
    "len(abag), len(nbag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(nbag): 1182\n",
      "type(nbag[0]): <class 'tuple'>\n",
      "type(nbag[0][0]): <class 'numpy.ndarray'>\n",
      "shape(nbag[0][0]): (2,)\n"
     ]
    }
   ],
   "source": [
    "print(\"len(nbag):\", len(nbag))\n",
    "print(\"type(nbag[0]):\", type(nbag[0]))\n",
    "\n",
    "# nbag[0]이 튜플/리스트면 feature가 보통 [0]에 있음\n",
    "try:\n",
    "    x0 = nbag[0][0]\n",
    "    print(\"type(nbag[0][0]):\", type(x0))\n",
    "    print(\"shape(nbag[0][0]):\", np.array(x0).shape)\n",
    "except Exception as e:\n",
    "    print(\"nbag[0][0] 접근 실패:\", e)\n",
    "    print(\"shape(nbag[0]):\", np.array(nbag[0]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The threshold of the score in step 1 is -19.88, abnormal part: 36\n",
      "The threshold of the score in step 2 is -19.53, abnormal part: 35\n",
      "The threshold of the score in step 3 is -19.18, abnormal part: 34\n",
      "The threshold of the score in step 4 is -19.05, abnormal part: 33\n",
      "The threshold of the score in step 5 is -18.95, abnormal part: 31\n",
      "The threshold of the score in step 6 is -18.98, abnormal part: 31\n",
      "The threshold of the score in step 7 is -18.87, abnormal part: 30\n",
      "The threshold of the score in step 8 is -18.74, abnormal part: 29\n",
      "The threshold of the score in step 9 is -18.47, abnormal part: 28\n",
      "The threshold of the score in step 10 is -18.30, abnormal part: 27\n",
      "The threshold of the score in step 11 is -18.24, abnormal part: 27\n",
      "The threshold of the score in step 12 is -18.13, abnormal part: 26\n",
      "The threshold of the score in step 13 is -17.96, abnormal part: 25\n",
      "0.14249253273010254\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nu = 1.0\n",
    "step = 1\n",
    "import time\n",
    "start = time.time()\n",
    "while len(abag) / len(nbag) < nu:\n",
    "    \n",
    "    temp_bag = nbag\n",
    "    X = np.vstack([np.asarray(t[0], dtype=np.float32).reshape(-1) for t in temp_bag])  # (N, 2)\n",
    "    y_gmm = gmm.fit_predict(X)\n",
    "    score = gmm.score_samples(X)\n",
    "\n",
    "    pct_threshold = np.percentile(score, 3) \n",
    "    res = np.array([1 if x < pct_threshold else 0 for x in score]) \n",
    "    print(f'The threshold of the score in step {step} is {pct_threshold:.2f}, abnormal part: {res.sum()}') \n",
    "    \n",
    "    abnormal_portion = np.where(res == 1)[0]\n",
    "    normal_portion = np.where(res == 0)[0]\n",
    "    # abnormal_portion / normal_portion 은 index 배열 (np.where 결과)\n",
    "    abag += [temp_bag[i] for i in abnormal_portion.tolist()]\n",
    "    nbag  = [temp_bag[i] for i in normal_portion.tolist()]\n",
    "    step += 1\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442,) 819\n",
      "correctness acc:  0.5396825396825397\n"
     ]
    }
   ],
   "source": [
    "print(np.where(np.array([x[1] for x in abag]) < 810)[0].shape, len([x[1] for x in abag]))\n",
    "print('correctness acc: ', np.where(np.array([x[1] for x in abag]) < 810)[0].shape[0] / len([x[1] for x in abag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422,) 790\n",
      "correctness acc:  0.5341772151898734\n"
     ]
    }
   ],
   "source": [
    "print(np.where(np.array([x[1] for x in nbag]) > 810)[0].shape, len([x[1] for x in nbag]))\n",
    "print('correctness acc: ', np.where(np.array([x[1] for x in nbag]) > 810)[0].shape[0] / len([x[1] for x in nbag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819.0, 1609)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [k[1] for k in sorted([(x[1], 1.0) for x in abag] + [(x[1], 0.0) for x in nbag], key=lambda z: z[0])]\n",
    "sum(temp), len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal set creation\n",
    "normal_set = {}\n",
    "\n",
    "for i in range(len(new_repr)):\n",
    "    if temp[i] == 0.0:\n",
    "        normal_set[i] = new_repr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abnormal set creation\n",
    "abnormal_set = {}\n",
    "for i in range(len(new_repr)):\n",
    "    if temp[i] == 1.0:\n",
    "        abnormal_set[i] = new_repr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norms_N = np.empty(0,)\n",
    "for (idel, sample) in normal_set.items():\n",
    "    \n",
    "    # print(sample.shape)\n",
    "    \n",
    "\n",
    "    l2_norms_N = np.append(l2_norms_N,get_matrix(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(790, 819)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_set), len(abnormal_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_GMM, var_GMM = estimate_gauss(np.array(l2_norms_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability model\n",
    "from scipy.stats import multivariate_normal\n",
    "p = multivariate_normal(mu_GMM, var_GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {} \n",
    "length = 0.2 \n",
    "for (idel, sample) in abnormal_set.items(): \n",
    "\n",
    "    # feature extraction \n",
    "    # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "    sample_matrix = get_matrix(sample)\n",
    "    \n",
    "    # get p values\n",
    "    probs = p.pdf(sample_matrix)\n",
    "    temp_list = []\n",
    "    temp_list += [0.0] * len(probs)\n",
    "    \n",
    "    window_size = int(len(probs) * length)  # fixed\n",
    "    temp = []\n",
    "    for idx in range(0, len(probs) - window_size + 1):\n",
    "        arr = 0\n",
    "        for i in range(idx, idx + window_size - 1):\n",
    "            arr += abs(probs[i+1] - probs[i])\n",
    "        temp.append(arr)\n",
    "\n",
    "    for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "        temp_list[i] = 1.0\n",
    "\n",
    "    ground_truth[idel] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gt = []\n",
    "abnormal_gt = []\n",
    "for i in range(len(new_repr)):\n",
    "    if i in normal_set.keys():\n",
    "        final_gt += [0.0] * new_repr[i].shape[0]\n",
    "    else:\n",
    "        final_gt += ground_truth[i]\n",
    "        abnormal_gt+= ground_truth[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779951"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_gt shape: (779951,) sum: 57267.0\n"
     ]
    }
   ],
   "source": [
    "final_gt = np.array(final_gt, dtype=np.float32)\n",
    "\n",
    "print(\"final_gt shape:\", final_gt.shape, \"sum:\", final_gt.sum())\n",
    "np.save(r\"..\\Unsup_labels\\UCF_unsup_labels_i3d_varT.npy\", final_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final abag: 819 nbag: 790 ratio: 1.0367088607594936\n"
     ]
    }
   ],
   "source": [
    "print(\"final abag:\", len(abag), \"nbag:\", len(nbag), \"ratio:\", len(abag)/len(nbag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779951,) float32\n",
      "mean: 0.07342384 sum: 57267.0\n",
      "ones ratio: 0.07342384\n"
     ]
    }
   ],
   "source": [
    "pseudo = np.load(\"../Unsup_labels/UCF_unsup_labels_i3d_varT.npy\")\n",
    "print(pseudo.shape, pseudo.dtype)\n",
    "print(\"mean:\", pseudo.mean(), \"sum:\", pseudo.sum()) #sum 결과 = 전체 스니펫(779951개) 중 약 5.7만 개를 이상(1)으로 찍었음을 알 수 있음. \n",
    "print(\"ones ratio:\", pseudo.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('unsupervised_PL/'+'UCF_labels_entropy_1.npy', final_gt) #UCF\n",
    "# np.save('Unsup_labels/'+'XD_I3D_unsup_labels_10_V2_GMM.npy', final_gt) #XD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c2fpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
